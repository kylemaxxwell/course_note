# Course of Getting and Cleaning Data Notes
Version 1.0

----------
## The Tidy Data 
1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

## The Code Book
1. Information about the variables (including units!) in the data set not contained in the tidy data
2. Information about the summary choices you made
3. Information about the experimental study design you used

## Downloading Files
- SET working directory  
	Relative - `setwd("./data"); setwd("../")`  
	Absolute - `setwd("/Users/kyle/data/")`  
	Note: Windows - `setwd("C:\\Users\\Downloads")`
- Check directory  

	```r
	if ( !file.exists("data")){ # Check to see if the directory   exists  
		dir.create("data")      # Create a directory if it doesn't   exist  
	}
	```
- Download file  

	```r
	url <- "https://....."
	## Url starts with *https* on Mac -- *method = "curl"*	
	download.file(url, destfile = "./data/some.csv", method = "curl")
	list.files("./data")
	dataDownloaded <- date()
	```
	- Deal with https download on Windows

	```r
	## Method 1
	fileURL <- sub('https', 'http', url)
	## Method 2
	library(RCurl)
	```

## Reading Files
TYPE|USAGE
:-:|---
**Flat**|`read.table("./data.csv",sep=",",header=TRUE)`<BR>`read.csv()`<BR>`read.csv2()`<BR>**Important parameters**<BR>`quote=""` means no quotes<BR>`na.strings="$"` set "$" to missing value<BR>`nrows=10` reads 10 lines<BR>`skip=2` don't read line 2
**Excel**|`library(xlsx)`<BR>`read.xlsx("./data.xlsx",sheetIndex=1,colIndex=2:3,rowIndex=1:4)`<BR>`write.xlsx()` write out an Excel file<BR>`read.xlsx2()` faster than *read.xlsx* for reading subsets of rows and slightly unstable<BR>`library(XLConnect)` [XLConnect](http://cran.r-project.org/web/packages/XLConnect/index.html) package has more options for writing and manipulating Excel files<BR>[XLConnect vignette](http://cran.r-project.org/web/packages/XLConnect/vignettes/XLConnect.pdf)
**XML**|**Read the file into R**<BR>`library(XML)`<BR>`url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"`<BR>`url<-sub("https","http",url)`<BR>`doc<-xmlTreeParse(url,useInternal=TRUE) #OR doc<-xmlInternalTreeParse(url)`<BR>`rootNode<-xmlRoot(doc)`<BR>`xmlName(rootNode)`<BR>**Directly access parts of the XML document**<BR>`rootNode[[1]] #OR xmlChildren(rootNode)[[1]]`<BR>`rootNode[[1]][[1]]`<BR>**Programatically extract parts of the file**<BR>`xmlSApply(rootNode[[1]],function(x) xmlValue(x[["zipcode"]])) # With attribute "names"`<BR>**XPath**<BR>`xpathSApply(rootNode[[1]],"//response/row/row/zipcode",xmlValue) # No attribute`<BR><BR>`"/node"` top level node<BR>`"//node"` node at any level<BR>`"node[@attr-name]"` node with attribute name<BR>`"node[@attr-name='bob']"` node with attribute name attr-name='bob'<BR>**Extract content by attributes**<BR>`fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"`<BR>`doc <- htmlTreeParse(fileUrl,useInternal=TRUE)`<BR>`scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)`<BR>`teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)`<BR>Official XML tutorials [short](http://www.omegahat.org/RSXML/shortIntro.pdf), [long](http://www.omegahat.org/RSXML/Tour.pdf)<BR>**Notes and further resources**<BR>[An outstanding guide to the XML package](http://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf)
**JSON**|**Reading data from JSON {jsonlite package}**<BR>`library(jsonlite)`<BR>`fromJSON(url)`<BR>**Writing data frames to JSON**<BR>`json<-toJSON(iris,pretty=TRUE)`<BR>`cat(json)`<BR>**Convert back to JSON**<BR>`iris2 <- fromJSON(myjson)`<BR>**Further resources**<BR>[http://www.json.org/](http://www.json.org/)<BR>A good [tutorial](http://www.r-bloggers.com/new-package-jsonlite-a-smarter-json-encoderdecoder/) on jsonlite<BR>[jsonlite vignette](http://cran.r-project.org/web/packages/jsonlite/vignettes/json-mapping.pdf)
**MySQL**|**Connecting and listing databases**<BR>`library(RMySQL)`<BR>`ucscDb<-dbCOnnect(MySQL(),user="genome",host="genome-mysql.cse.ucsc.edu")`<BR>`result<-dbGetQuery(ucscDb,"show databases;")`<BR>`dbDisconnect(ucscDb)`<BR>**Connecting to hg19 and listing tables**<BR>`hg19<-dbCOnnect(MySQL(),user="genome",db="hg19",host="genome-mysql.cse.ucsc.edu")`<BR>`dbLIstTables(hg19)`<BR>`dbLIstFields(hg19,"affyU133Plus2")`<BR>`dbGetQuery(hg19,"select count(*) from affyU133Plus2"`<BR>**Read from the table**<BR>`affyData<-dbReadTable(hg19,"affyU133Plus2")`<BR>**Select a specific subset**<BR>`query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")`<BR>`affyMis <- fetch(query)`<BR>`affyMisSmall <- fetch(query,n=10); dbClearResult(query)`<BR>`dbDisconnect(hg19)`<BR>**Further resources**<BR>RMySQL vignette [RMySQL.pdf](http://cran.r-project.org/web/packages/RMySQL/RMySQL.pdf)<BR>[List of commands](http://www.pantz.org/software/mysql/mysqlcommands.html)<BR>A nice [blog](http://www.r-bloggers.com/mysql-and-r/) post summarizing some other commands
**HDF5**|**R HDF5 package**<BR>`source("http://bioconductor.org/biocLite.R")`<BR>`biocLite("rhdf5")`<BR>`library(rhdf5)`<BR>`created = h5createFile("example.h5")`<BR>[rhdf5 tutorial](http://www.bioconductor.org/packages/release/bioc/vignettes/rhdf5/inst/doc/rhdf5.pdf)<BR>**Create groups**<BR>`created = h5createGroup("example.h5","foo")`<BR>`created = h5createGroup("example.h5","baa")`<BR>`created = h5createGroup("example.h5","foo/foobaa")`<BR>`h5ls("example.h5")`<BR>**Write to groups**<BR>`A = matrix(1:10,nr=5,nc=2)`<BR>`h5write(A, "example.h5","foo/A")`<BR>`B = array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))`<BR>`attr(B, "scale") <- "liter"`<BR>`h5write(B, "example.h5","foo/foobaa/B")`<BR>`h5ls("example.h5")`<BR>**Write a data set**<BR>`df = data.frame(1L:5L,seq(0,1,length.out=5), c("ab","cde","fghi","a","s"), stringsAsFactors=FALSE)`<BR>`h5write(df, "example.h5","df")`<BR>`h5ls("example.h5")`<BR>**Reading data**<BR>`readA = h5read("example.h5","foo/A")`<BR>`readB = h5read("example.h5","foo/foobaa/B")`<BR>`readdf= h5read("example.h5","df")`<BR>**Writing and reading chunks**<BR>`h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))`<BR>`h5read("example.h5","foo/A")`<BR>**Notes and further resources**<BR>primarily used for genomics but also has good "big data" packages<BR>* hdf5 can be used to optimize reading/writing from disc in R<BR>The rhdf5 tutorial: [rhdf5.pdf](http://www.bioconductor.org/packages/release/bioc/vignettes/rhdf5/inst/doc/rhdf5.pdf)<BR>* The HDF group has informaton on HDF5 in general [http://www.hdfgroup.org/HDF5/](http://www.hdfgroup.org/HDF5/)
**Web**|**Getting data off webpages - readLines()**<BR>`con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")`<BR>`htmlCode = readLines(con)`<BR>`close(con)`<BR>**Parsing with XML**<BR>`library(XML)`<BR>`url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"`<BR>`html <- htmlTreeParse(url, useInternalNodes=T)`<BR>`xpathSApply(html, "//title", xmlValue)`<BR>`xpathSApply(html, "//td[@id='col-citedby']", xmlValue)`<BR>**GET from the httr package**<BR>`library(httr); html2 = GET(url)`<BR>`content2 = content(html2,as="text")`<BR>`parsedHtml = htmlParse(content2,asText=TRUE)`<BR>`xpathSApply(parsedHtml, "//title", xmlValue)`<BR>**Accessing websites with passwords**<BR>`pg2 = GET("http://httpbin.org/basic-auth/user/passwd",authenticate("user","passwd"))`<BR>**Using handles**<BR>`google = handle("http://google.com")`<BR>`pg1 = GET(handle=google,path="/")`<BR>`pg2 = GET(handle=google,path="search")`<BR>**Notes and further resources**<BR>* R Bloggers has a number of examples of web scraping [Web Scraping](http://www.r-bloggers.com/?s=Web+Scraping)<BR>* The httr help file has useful examples [httr.pdf](http://cran.r-project.org/web/packages/httr/httr.pdf)
**APIs**|**Find OAuth settings for [github](http://developer.github.com/v3/oauth/)**<BR>`oauth_endpoints("github")`<BR>**To make your own application, register at at [here](https://github.com/settings/applications). Use any URL for the homepage URL(http://github.com is fine) and http://localhost:1410 as the callback url**<BR>`myapp <- oauth_app("My Application",key = "-Client ID-",secret = "-Client Secret-")`<BR>**Get OAuth credentials & Use API**<BR>`github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)`<BR>`gtoken <- config(token = github_token)`<BR>`req <- GET("https://api.github.com/users/jtleek/repos", gtoken)`<BR># OR:<BR>`req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))`<BR>`stop_for_status(req)`<BR>**With Token**<BR>`sig = sign_oauth1.0(myapp,token = "yourTokenHere",token_secret = "yourTokenSecretHere")`<BR>`req = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)`<BR><BR>`json1<-content(req)`<BR>`json2<-fromJSON(toJSON(json1))`<BR>`json2[json2$name=="datasharing","created_at"]`
**Others**|**Package "foreign"**<BR>Basic functions `read.foo()` [details](http://cran.r-project.org/web/packages/foreign/foreign.pdf)<BR>**Database packages**<BR>*RPostresSQL* provides a DBI-compliant database connection from R [Tutorial](https://code.google.com/p/rpostgresql/), help file-[RPostgreSQL.pdf](http://cran.r-project.org/web/packages/RPostgreSQL/RPostgreSQL.pdf)<BR>*RODBC* provides interfaces to multiple databases including PostgreQL, MySQL, Microsoft Access and SQLite. Tutorial - [RODBC.pdf](http://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf), help file - [RODBC.pdf](http://cran.r-project.org/web/packages/RODBC/RODBC.pdf)<BR>*RMongo* [RMongo.pdf](http://cran.r-project.org/web/packages/RMongo/RMongo.pdf) ([example of Rmongo](http://www.r-bloggers.com/r-and-mongodb/)) and [Interfaces to MongoDb](http://cran.r-project.org/web/packages/rmongodb/rmongodb.pdf)<BR>**Reading images**<BR>[jpeg](http://cran.r-project.org/web/packages/jpeg/index.html) [readbitmap](http://cran.r-project.org/web/packages/readbitmap/index.html) [png](http://cran.r-project.org/web/packages/png/index.html) [EBImage (Bioconductor)](http://www.bioconductor.org/packages/2.13/bioc/html/EBImage.html)<BR>**Reading GIS data**<BR>[rgdal](http://cran.r-project.org/web/packages/rgdal/index.html) [rgeos](http://cran.r-project.org/web/packages/rgeos/index.html) [raster](http://cran.r-project.org/web/packages/raster/index.html)<BR>**Reading music data**<BR>[tuneR](http://cran.r-project.org/web/packages/tuneR/) [seewave](http://rug.mnhn.fr/seewave/)

## data.table vs. dplyr in simple

-|data.table|dplyr
:-:|---|---
**F<BR>O<BR>R<BR>M**|`DT[i, j, by]`<BR>The way to read it (out loud) is:<BR>Take DT, subset rows using i, then calculate j, grouped by by|-
**R<BR>E<BR>A<BR>D**|`flights <- fread("https://raw.githubusercontent.com/wiki/`<BR>`arunsrinivasan/flights/NYCflights14/flights14.csv")`|-
**R<BR>O<BR>W**|**a) Subset rows in i**<BR>`ans <- DT[origin == "JFK" & month == 6L]`<BR>`ans <- DT[1:2] # Get the first two rows from DT`|–
**S<BR>O<BR>R<BR>T**|– Sort DT first by column origin in ascending order,<BR>–– and then by dest in descending order<BR>`ans <- DT[order(origin, -dest)]`|-
**C<BR>O<BR>L<BR>U<BR>M<BR>N**|**a) Select column(s) in j**<BR>– Select arr column, but return it as a *vector*<BR>`ans <- DT[, arr]`<BR>– Select arr column, but return as a *data.table* instead<BR>`ans <- DT[, list(arr)]`<BR>– Select both arr and dep columns<BR>`ans <- DT[, .(arr, dep)]`<BR>: Wrap both columns within `.()`, or `list()`<BR>– Select both arr and dep columns<BR>–– and rename them to _arr and _dep.<BR>`ans <- DT[, .(_arr = arr, _dep = dep)]`<BR><BR>**b) Compute or *do* in j**<BR>`ans <- DT[, sum((arr + dep) < 0)]`<BR><BR>**c) Subset in i *and* do in j**<BR>`ans <- DT[origin == "JFK" & month == 6L,`<BR>`.(m_arr=mean(arr), m_dep=mean(dep))]`<BR>– How many trips from “JFK” airport in the month of June?<BR>– Compute the number of rows used any other column<BR>`ans <- DT[origin == "JFK" & month == 6L, length(dest)]`<BR>`ans <- DT[origin == "JFK" & month == 6L, .N] #same to above`<BR>– Select both arr and dep columns the *data.frame* way<BR>–– using `with = FALSE`.<BR>`ans <- flights[, c("arr", "dep"), with=FALSE]`<BR>`# returns all columns except arr and dep`<BR>`ans <- DS[, !c("arr", "dep"), with=FALSE]`<BR>`# or`<BR>`ans <- DS[, -c("arr", "dep"), with=FALSE]`<BR>–– Select by specifying start and end column names<BR>`# returns year,month and day`<BR>`ans <- DS[, year:day, with=FALSE]`<BR><BR>**d) The := operator**<BR>a. The LHS := RHS form<BR>`DT[, c("colA", "colB", ...) := list(valA, valB, ...)]`<BR>`DT[, colA := valA] # only one column to assign`<BR>b. The functional form<BR>`DT[, `:=`(colA = valA, # valA is assigned to colA`<BR>`colB = valB, # valB is assigned to colB`<BR>`...`<BR>`)]`<BR><BR>**e) Add columns by reference**<BR>`DT[, `:=`(speed = distance / (air_time/60), # speed in km/hr`<BR>`delay = arr + dep)]   # delay in minutes`<BR>`## alternatively, using the 'LHS := RHS' form`<BR>`DT[,c("speed","delay"):=list(distance/(time/60),arr+dep)]`<BR><BR>**f) Update some rows of columns by reference**<BR>– Replace those rows where hour == 24 with the value 0<BR>`DT[hour == 24L, hour := 0L]`<BR>`:=` returns the result invisibly. adding an empty `[]` to see the result after the assignment:<BR>`DT[hour == 24L, hour := 0L][]`<BR><BR>**g) Delete column by reference**<BR>`DT[, c("delay") := NULL]`<BR>`## or using the functional form`<BR>`DT[, `\``:=`\``(delay = NULL)]`<BR>– When there is just one column to delete<BR>`DT[, delay := NULL]`<BR><BR>**h) `:=` along with grouping using `by`**<BR>– Contains for each orig,dest pair the maximum speed<BR>`DT[, max_speed := max(speed), by=.(origin, dest)]`<BR><BR>**i) Multiple columns and `:=`**<BR>– Add two columns computing max() of dep_delay and arr_delay for each month<BR>`in_col  = c("dep", "arr")`<BR>`out_col = c("max_dep", "max_arr")`<BR>`DT[,c(out_col):= lapply(.SD,max),by=month,.SDcols=in_col]`<BR><BR>**j) `:=` and `copy()`**<BR>**j.a) `:=` for its side effect**<BR>`foo <- function(DT) {`<BR>`--DT[, speed := distance / (air_time/60)]`<BR>`--DT[, .(max_speed = max(speed)), by=month]`<BR>`}`<BR>`ans = foo(flights) #modifying DT also reflects on flights`<BR><BR>**j.b) The `copy()` function**<BR>`foo <- function(DT) {`<BR>`--DT <- copy(DT) ## deep copy`<BR>`--DT[,speed:=distance/(air_time/60)] ## doesn't affect flights`<BR>`--DT[, .(max_speed = max(speed)), by=month]`<BR>`}`<BR>`ans <- foo(flights)`|-
**A<BR>G<BR>G<BR>R<BR>E<BR>G<BR>A<BR>T<BR>I<BR>O<BR>N<BR>S**|**a) Grouping using *by***<BR>– Get the number corresponding to each origin<BR>`ans <- DT[, .(.N), by=.(origin)]`<BR>`# or`<BR>`ans <- DT[, .(.N), by="origin"]`<BR>`# only one column/expression to refer to in j and by,`<BR>`# can drop the .() notation`<BR>`ans <- DT[, .N, by=origin]`<BR>– Calculate the number for each origin for carrier == “AA”<BR>`ans <- DT[carrier == "AA", .N, by=origin]`<BR>– Total number each origin, dest pair for carrier == “AA”<BR>`ans <- DT[carrier == "AA", .N, by=.(origin,dest)]`<BR>`## or equivalently using a character vector in 'by'`<BR>`ans <- DT[carrier == "AA", .N, by=c("origin", "dest")]`<BR>– Average *arr* & *dep* for each orig,dest pair for each month<BR>–– for `carrier == "AA"`<BR>`ans <- DT[carrier == "AA", .(mean(arr), mean(dep)),`<BR>` by=.(origin, dest, month)]`<BR><BR>**b) keyby**<BR>– Order by all the grouping variables<BR>`ans <- DT[carrier == "AA", .(mean(arr), mean(dep)),`<BR>`keyby=.(origin, dest, month)]`<BR><BR>**c) Chaining**<BR>`ans <- DT[carrier == "AA", .N,`<BR>` by=.(origin, dest)][order(origin, -dest)]`<BR>`DT[ ... ][ ... ][ ... ]`<BR><BR>**d) Expressions in `by`**<BR>`ans <- DT[, .N, .(dep>0, arr>0)]`<BR><BR>**e) Multiple columns in `j` - `.SD`**<BR>Special symbol .SD: stands for **S**ubset of **D**ata<BR>`#.SD contains all the columns`<BR>` # except the grouping columns by default.`<BR>`DT[, print(.SD), by=ID]`<BR>`# Compute on (multiple) columns`<BR>`DT[, lapply(.SD, mean), by=ID]`<BR>Specify just the columns we would like to compute<BR>`DT[carrier == "AA", ## Only on trips with carrier "AA"`<BR>`lapply(.SD, mean), ## compute the mean`<BR>`by=.(origin, dest, month), ## for every 'origin,dest,month'`<BR>`.SDcols=c("arr", "dep")] ## just those specified in .SDcols`<BR><BR>**f) Subset .SD for each group:**<BR>– How can we return the first two rows for each month?<BR>`ans <- DT[, head(.SD, 2), by=month]`<BR>– Concatenate columns a and b for each group in ID<BR>`DT = data.table(ID = c("b","b","b","a","a","c"),`<BR>` a = 1:6, b = 7:12, c=13:18)`<BR>`DT[, .(val = c(a,b)), by=ID]`<BR>– Have all the values of column a and b concatenated,<BR>–– but returned as a list column<BR>`DT[, .(val = list(c(a,b))), by=ID]`<BR>`## (1) look at the difference between`<BR>`DT[, print(c(a,b)), by=ID]`<BR>`## (2) and`<BR>`DT[, print(list(c(a,b))), by=ID]`<BR>In (1),for each group,a *vector* is returned,length = 6,4,2 here.<BR>However (2) returns a *list* of length 1 for each group, <BR>with its first element holding vectors of length 6,4,2.<BR>Therefore (1) results in a length of 6+4+2 = 12,<BR> whereas (2) returns 1+1+1=3.|-
**S<BR>U<BR>M<BR>M<BR>A<BR>R<BR>Y**|The general form of *data.table* syntax is:<BR>`DT[i, j, by]`<BR>**Using i:**<BR>We can subset rows similar to a data.frame - except you don’t have to use `DT$` repetitively since columns within the frame of a *data.table* are seen as if they are *variables*.<BR>We can also sort a *data.table* using `order()`, which internally uses data.table’s fast order for performance.<BR>We can do much more in `i` by keying a *data.table*, which allows blazing fast subsets and joins. We will see this in the “*Keys and fast binary search based subsets*” and “*Joins and rolling joins*” vignette.<BR><BR>**Using j:**<BR>1. Select columns the data.table way: `DT[, .(colA, colB)]`.<BR>2. Select columns the data.frame way: `DT[, c("colA", "colB"), with=FALSE]`.<BR>3. Compute on columns: `DT[, .(sum(colA), mean(colB))]`.<BR>4. Provide names if necessary: `DT[, .(sA =sum(colA), mB = mean(colB))]`.<BR>5. Combine with i: `DT[colA > value, sum(colB)]`.<BR><BR>**Using by:**<BR>Using `by`, we can group by columns by specifying a *list of columns or a character vector of column names or even expressions*. The flexibility of `j`, combined with `by` and `i` makes for a very powerful syntax.<BR>`by` can handle multiple columns and also *expressions*.<BR>We can `keyby` grouping columns to automatically sort the grouped result.<BR>We can use `.SD` and `.SDcols` in j to operate on multiple columns using already familiar base functions. Here are some examples:<BR>1.` DT[, lapply(.SD, fun), by=., .SDcols=...]` - applies `fun` to all columns specified in `.SDcols` while grouping by the columns specified in `by`.<BR>2. `DT[, head(.SD, 2), by=.]` - return the first two rows for each group.<BR>`DT[col > val, head(.SD, 1), by=.]` - combine `i` along with `j` and `by`.<BR>|-
**S<BR>U<BR>B<BR>S<BR>E<BR>T**|**1. Keys**<BR>**a) What is a *key*?**<BR>`DF = data.frame(ID1 = sample(letters[1:2], 10, TRUE),`<BR>`ID2 = sample(1:3, 10, TRUE),val = sample(10),`<BR>`stringsAsFactors = FALSE,row.names = sample(LETTERS[1:10]))`<BR>`rownames(DF)`<BR>`#  [1] "C" "D" "E" "G" "B" "H" "I" "F" "J" "A"`<BR>Each row is limited to *exactly* one row name.<BR>And row names should be *unique*.<BR>`rownames(DF) = sample(LETTERS[1:5], 10, TRUE) #Error`<BR>`DT = as.data.table(DF)`<BR>`rownames(DT)`<BR>`#  [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10"`<BR>Use `keep.rownames = TRUE` in `as.data.table()` - this will create a new column called `rn` and assign row names to this column.<BR><BR>**b) Set, get and use keys on a `data.table `**<BR>– Set the column origin as key in the data.table flights<BR>`setkey(DT, origin)`<BR>`## OR provide character vectors to the function 'setkeyv()'`<BR>`setkeyv(DT, "origin") # useful to program with`<BR>– Use the key column origin to subset all rows where the origin airport matches “JFK”<BR>`DT[.("JFK")]`<BR>`## alternatively`<BR>`DT[J("JFK")]` or `DT[list("JFK")]`<BR>`## On single column key of character type`<BR>`DT["JFK"] ## same as DT[.("JFK")]`<BR>`DT[c("JFK", "LGA")]    ## same as DT[.(c("JFK", "LGA"))]`<BR>+ setX and `:=` :<BR>In data.table, the `:=` operator and all the setX (e.g., `setkey`, `setorder`, `setnames` etc..) functions are the only ones which modify the input object by reference.<BR>– Get the column(s) a data.table is keyed by<BR>`key(DT)`<BR>`# [1] "origin"`<BR><BR>**c) Keys and multiple columns**<BR>– Set keys on both origin and dest columns<BR>`setkey(DT, origin, dest)`<BR>`## OR provide a character vector of column names`<BR>`setkeyv(DT, c("origin", "dest"))`<BR>+ It sorts the *data.table* first by the column `origin` and then by `dest` by reference.<BR>– Subset all rows using key columns where first key column origin matches “JFK” and second key column dest matches “MIA”<BR>`DT[.("JFK", "MIA")]`<BR>– Subset all rows where just the first key column origin matches “JFK”<BR>`DT[.("JFK")]`<BR>– Subset all rows where just the second key column `dest` matches “MIA”<BR>`DT[.(unique(origin), "MIA")]`<BR><BR>**2) Combining keys with `j` and `by`**<BR>**a) Select in j**<BR>– Return arr column as a *data.table* corresponding to origin = "LGA" and dest = "TPA".<BR>`DT[.("LGA", "TPA"), .(arr)]`<BR>`DT[.("LGA", "TPA"), "arr", with=FALSE] # return result`<BR><BR>**b) Chaining**<BR>– Use chaining to order the column in decreasing order.<BR>`DT[.("LGA", "TPA"), .(arr)][order(-arr)]`<BR><BR>**c) Compute or do in j**<BR>– Find the maximum arrival delay correspondong to origin = "LGA" and dest = "TPA".<BR>`DT[.("LGA", "TPA"), max(arr)]`<BR>`# [1] 486`<BR><BR>**d) sub-assign by reference using `:=` in j**<BR>`# get all 'hours' in flights`<BR>`DT[, sort(unique(hour))]`<BR>`#  [1]  0  1  2  3 ... 21 22 23 24`<BR>`setkey(DT, hour)`<BR>`key(DT)`<BR>`# [1] "hour"`<BR>`DT[.(24), hour := 0L]`<BR>`key(DT)`<BR>`# NULL`<BR>+ Since we have replaced values on the key column, the *data.table* DT isn’t sorted by hour anymore. Therefore, the key has been automatically **removed** by setting to NULL.<BR><BR>**e) Aggregation using by**<BR>`setkey(DT, origin, dest)`<BR>– Get the maximum departure delay for each month corresponding to origin = "JFK". Order the result by month<BR>`ans <- DT["JFK", max(dep), keyby=month]`<BR>`key(ans)`<BR>`# [1] "month"`<BR>+ Also sets month as the key column<BR><BR>**3) Additional arguments - *mult* and *nomatch* **<BR>**a) The *mult* argument**<BR>– Subset only the **first matching** row from all rows where origin matches “JFK” and dest matches “MIA”<BR>`DT[.("JFK", "MIA"), mult="first"]`<BR>– Subset only the **last matching **row of all the rows where origin matches “LGA”, “JFK”, “EWR” and dest matches “XNA”<BR>`DT[.(c("LGA", "JFK", "EWR"), "XNA"), mult="last"]`<BR>+ The query “JFK”, “XNA” **doesn’t match** any rows in flights and therefore returns **NA**.<BR>+ Once again, the query for second key column dest, “XNA”, is **recycled** to fit the length of the query for **first key column origin**, which is of length 3.<BR><BR>**b) The nomatch argument**<BR>– From the previous example, Subset all rows only if there’s a match<BR>`DT[.(c("LGA", "JFK", "EWR"), "XNA"), mult="last", nomatch = 0L]`<BR>+ Default value for nomatch is NA. Setting nomatch = 0L **skips queries** with no matches.<BR><BR>**4) binary search vs vector scans**<BR>`# key by origin,dest columns`<BR>`DT[.("JFK", "MIA")]`<BR>`# we could have done:`<BR>`DT[origin == "JFK" & dest == "MIA"]`